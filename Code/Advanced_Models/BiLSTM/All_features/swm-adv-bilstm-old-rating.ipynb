{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIJjlEdZigV1",
        "outputId": "d53a8877-d550-4452-8a4d-2ffde5eade66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iMPRZMysij1_"
      },
      "outputs": [],
      "source": [
        "!pip install wget\n",
        "!pip install keras_preprocessing\n",
        "!pip install keras_tuner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "TwYmLcU8iHob"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "from tqdm import tqdm\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, LSTM, Dense, SpatialDropout1D, Dropout, Bidirectional, Input, Concatenate, concatenate\n",
        "from keras.initializers import Constant\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.optimizers import Adam\n",
        "import tensorflow as tf\n",
        "import keras_tuner as kt\n",
        "from keras.models import Model\n",
        "\n",
        "import os.path\n",
        "import wget\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "4bXyVUvCiLLY"
      },
      "outputs": [],
      "source": [
        "def assign_class(label):\n",
        "    if label == \"OR\":\n",
        "        return 0\n",
        "    else:\n",
        "        return 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Sr1lsLTs-V8u"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
        "\n",
        "def evaluate_model(y_prob, y_test):\n",
        "    y_pred = np.round(y_prob)\n",
        "    y_true = y_test\n",
        "\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred)\n",
        "    recall = recall_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    roc_auc = roc_auc_score(y_test, y_prob, multi_class='ovr')\n",
        "\n",
        "    metrics = {'accuracy': accuracy,\n",
        "               'precision': precision,\n",
        "               'recall': recall,\n",
        "               'f1': f1,\n",
        "               'confusion_matrix': cm,\n",
        "               'roc_auc': roc_auc}\n",
        "\n",
        "    return metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "9juLa5ghPlDo"
      },
      "outputs": [],
      "source": [
        "# import and extract information \n",
        "\n",
        "ori_train_data = pd.read_csv('/content/drive/MyDrive/swm-data/ori_data_final_train.csv')\n",
        "ori_valid_data = pd.read_csv('/content/drive/MyDrive/swm-data/ori_data_final_val.csv')\n",
        "ori_test_data = pd.read_csv('/content/drive/MyDrive/swm-data/ori_data_final_test.csv')\n",
        "\n",
        "ori_train_data['label_final'] = ori_train_data['label'].apply(assign_class)\n",
        "ori_valid_data['label_final'] = ori_valid_data['label'].apply(assign_class)\n",
        "ori_test_data['label_final'] = ori_test_data['label'].apply(assign_class)\n",
        "\n",
        "ori_train_data.category = pd.factorize(ori_train_data.category)[0]\n",
        "ori_test_data.category = pd.factorize(ori_test_data.category)[0]\n",
        "ori_valid_data.category = pd.factorize(ori_valid_data.category)[0]\n",
        "category_indices = pd.factorize(ori_train_data.category)[1]\n",
        "\n",
        "x_train_review = ori_train_data.text_final\n",
        "x_train_rating = ori_train_data.rating\n",
        "x_train_category = ori_train_data.category\n",
        "x_train_word_category = ori_train_data.word_count_categories\n",
        "\n",
        "x_test_review = ori_test_data.text_final\n",
        "x_test_rating = ori_test_data.rating\n",
        "x_test_category = ori_test_data.category\n",
        "x_test_word_category = ori_test_data.word_count_categories\n",
        "\n",
        "\n",
        "x_val_review = ori_valid_data.text_final\n",
        "x_val_rating = ori_valid_data.rating\n",
        "x_val_category = ori_valid_data.category\n",
        "x_val_word_category = ori_valid_data.word_count_categories\n",
        "\n",
        "\n",
        "y_train = ori_train_data.label_final\n",
        "y_test = ori_test_data.label_final\n",
        "y_val = ori_valid_data.label_final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "8tmiJVnsPlDq"
      },
      "outputs": [],
      "source": [
        "# create vocab \n",
        "\n",
        "vocab_size = 20000\n",
        "oov_token = \"\"\n",
        "max_length = 200\n",
        "padding_type = \"post\"\n",
        "trunc_type = \"post\"\n",
        "\n",
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_token)\n",
        "tokenizer.fit_on_texts(x_train_review) \n",
        "\n",
        "x_train_review_pad = pad_sequences(tokenizer.texts_to_sequences(\n",
        "    x_train_review), maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "x_test_review_pad = pad_sequences(tokenizer.texts_to_sequences(\n",
        "    x_test_review), maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "x_val_review_pad = pad_sequences(tokenizer.texts_to_sequences(\n",
        "    x_val_review), maxlen=max_length, padding=padding_type, truncating=trunc_type)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UExRb0kJPlDq",
        "outputId": "05052420-78d3-4a88-f31a-dc39119dc8e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 400000 word vectors.\n",
            "Converted 30442 words (7491 misses)\n"
          ]
        }
      ],
      "source": [
        "# if not os.path.isfile('/content/drive/MyDrive/swm-data/glove.6B.@00d.txt'):\n",
        "#     # large file, might take a while to download :)\n",
        "#     url = 'http://nlp.stanford.edu/data/glove.6B.zip'\n",
        "#     print('Downloading Pre-trained Word Embeddings')\n",
        "#     wget.download(url)\n",
        "#     print('Download Completed!\\nUnzipping...')\n",
        "#     shutil.unpack_archive('glove.6B.zip')\n",
        "\n",
        "embeddings_index = {}\n",
        "with open(\"/content/drive/MyDrive/swm-data/glove.6B.200d.txt\") as f:\n",
        "    for line in f:\n",
        "        word, coefs = line.split(maxsplit=1)\n",
        "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
        "        embeddings_index[word] = coefs\n",
        "\n",
        "print(\"Found %s word vectors.\" % len(embeddings_index))\n",
        "\n",
        "num_tokens = len(tokenizer.word_index) + 2\n",
        "embedding_dim = 200\n",
        "hits = 0\n",
        "misses = 0\n",
        "\n",
        "# Prepare embedding matrix\n",
        "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # Words not found in embedding index will be all-zeros.\n",
        "        # This includes the representation for \"padding\" and \"OOV\"\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "        hits += 1\n",
        "    else:\n",
        "        misses += 1\n",
        "print(\"Converted %d words (%d misses)\" % (hits, misses))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "4ZAwqyozPlDr"
      },
      "outputs": [],
      "source": [
        "# create embedding layer \n",
        "import keras\n",
        "from keras.layers import Embedding\n",
        "\n",
        "embedding_layer = Embedding(\n",
        "    num_tokens,\n",
        "    embedding_dim,\n",
        "    embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
        "    trainable=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "rPr-MnCCPlDs"
      },
      "outputs": [],
      "source": [
        "def build_model(hp):\n",
        "\n",
        "    review_branch_input = Input(shape=(200,), name='review_input')\n",
        "    review_branch = embedding_layer(review_branch_input)\n",
        "    review_branch = Dropout(0.2)(review_branch)\n",
        "    review_branch = Bidirectional(\n",
        "        LSTM(64, dropout=0.2, recurrent_dropout=0))(review_branch)\n",
        "    review_branch = Dense(64, activation='relu')(review_branch)\n",
        "    review_branch_output = Dense(16, activation='relu')(review_branch)\n",
        "\n",
        "    rating_branch_input = Input(shape=(1,), name='rating_input')\n",
        "    rating_branch = Dense(8, activation='relu')(rating_branch_input)\n",
        "    rating_branch = Dropout(0.2)(rating_branch)\n",
        "    rating_branch_output = Dense(16, activation='relu')(rating_branch)\n",
        "\n",
        "    category_branch_input = Input(\n",
        "        shape=(1,), name='category_input')\n",
        "    category_branch = Dense(\n",
        "        8, activation='relu')(category_branch_input)\n",
        "    category_branch = Dropout(0.2)(category_branch)\n",
        "    category_branch_output = Dense(\n",
        "        16, activation='relu')(category_branch)\n",
        "\n",
        "    word_category_branch_input = Input(\n",
        "        shape=(1,), name='word_category_input')\n",
        "    word_category_branch = Dense(\n",
        "        8, activation='relu')(word_category_branch_input)\n",
        "    word_category_branch = Dropout(0.2)(word_category_branch)\n",
        "    word_category_branch_output = Dense(\n",
        "        16, activation='relu')(word_category_branch)\n",
        "\n",
        "    concat = concatenate([review_branch_output, rating_branch_output,\n",
        "                        category_branch_output, word_category_branch_output], name='Concatenate')\n",
        "\n",
        "    final_output = Dense(8, activation='relu')(concat)\n",
        "    final_output = Dense(1, activation='sigmoid')(final_output)\n",
        "\n",
        "    model = Model(inputs=[review_branch_input, rating_branch_input,\n",
        "                category_branch_input, word_category_branch_input], outputs=final_output, name='Final_output')\n",
        "\n",
        "    hp_learning_rate = hp.Float(\n",
        "        'learning_rate',\n",
        "        min_value=0.001,\n",
        "        max_value=0.005,\n",
        "        sampling='LOG',\n",
        "        default=1e-3\n",
        "    )\n",
        "\n",
        "    # clip value to avoid the gradient exploding\n",
        "    optimzer = Adam(clipvalue=0.5, learning_rate=hp_learning_rate)\n",
        "\n",
        "    model.compile(optimizer=optimzer,\n",
        "                loss='binary_crossentropy',\n",
        "                metrics=['acc'])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_BM5KlFPlDs",
        "outputId": "e6924693-1e08-418e-cb19-52ed32b7e575"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n"
          ]
        }
      ],
      "source": [
        "tuner = kt.BayesianOptimization(build_model,\n",
        "                    objective='val_acc',\n",
        "                    max_trials=5,\n",
        "                    directory='adl4nlp1',\n",
        "                    project_name='text_classification_bo')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-9aUGJ0PlDs",
        "outputId": "f297d0a7-d823-47a6-e221-5d535a1c8b29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Search space summary\n",
            "Default search space size: 1\n",
            "learning_rate (Float)\n",
            "{'default': 0.001, 'conditions': [], 'min_value': 0.001, 'max_value': 0.005, 'step': None, 'sampling': 'log'}\n"
          ]
        }
      ],
      "source": [
        "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)\n",
        "tuner.search_space_summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0VZQPU0PlDs",
        "outputId": "af4c32df-bc4c-4d6f-bdbc-16f1ca7aa3d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 5 Complete [00h 08m 28s]\n",
            "val_acc: 0.9201088547706604\n",
            "\n",
            "Best val_acc So Far: 0.9285184144973755\n",
            "Total elapsed time: 00h 39m 05s\n"
          ]
        }
      ],
      "source": [
        "tuner.search([x_train_review_pad,x_train_rating,x_train_category,x_train_word_category], y_train, epochs=5, \n",
        "         validation_data=([x_val_review_pad,x_val_rating,x_val_category,x_val_word_category], y_val),\n",
        "         callbacks=[stop_early,tf.keras.callbacks.TensorBoard(\"/tmp/tb_logs\")])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1DFY6GaPlDt",
        "outputId": "73d39308-93e8-4d3a-fd4a-8260af568876"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results summary\n",
            "Results in adl4nlp1/text_classification_bo\n",
            "Showing 10 best trials\n",
            "Objective(name=\"val_acc\", direction=\"max\")\n",
            "\n",
            "Trial 2 summary\n",
            "Hyperparameters:\n",
            "learning_rate: 0.0017359473597338057\n",
            "Score: 0.9285184144973755\n",
            "\n",
            "Trial 4 summary\n",
            "Hyperparameters:\n",
            "learning_rate: 0.0018875771755549177\n",
            "Score: 0.9201088547706604\n",
            "\n",
            "Trial 1 summary\n",
            "Hyperparameters:\n",
            "learning_rate: 0.002306059821977143\n",
            "Score: 0.9114518761634827\n",
            "\n",
            "Trial 0 summary\n",
            "Hyperparameters:\n",
            "learning_rate: 0.002474954869035655\n",
            "Score: 0.9102151989936829\n",
            "\n",
            "Trial 3 summary\n",
            "Hyperparameters:\n",
            "learning_rate: 0.0014057908432180079\n",
            "Score: 0.8953747153282166\n"
          ]
        }
      ],
      "source": [
        "tuner.results_summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "3l2QTbLSPlDv"
      },
      "outputs": [],
      "source": [
        "best_model = tuner.get_best_models(num_models=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "h-mRXVHIPlDv"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "tf.config.run_functions_eagerly(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUsez6DQPlDv",
        "outputId": "fa3bb95d-46e4-426c-d56e-e350d63c755d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "127/127 - 4s - loss: 0.1777 - acc: 0.9251 - 4s/epoch - 31ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.17767450213432312, 0.9250741600990295]"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# evaluate and save model \n",
        "\n",
        "best_model[0].evaluate([x_test_review_pad, x_test_rating, x_test_category, x_test_word_category], y_test, verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "wWXzlEx3PlDv"
      },
      "outputs": [],
      "source": [
        "best_model[0].save('/content/drive/MyDrive/swm-data/bilstm_old_tr.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0baEKXcPlDv",
        "outputId": "5568ee4f-8251-4507-f597-15b8f4199249"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "127/127 - 5s - loss: 0.1777 - acc: 0.9251 - 5s/epoch - 36ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.17767450213432312, 0.9250741600990295]"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Reload the model and verify the accuracy.\n",
        "\n",
        "model = tf.keras.models.load_model('/content/drive/MyDrive/swm-data/bilstm_old_tr.h5')\n",
        "model.evaluate([x_test_review_pad, x_test_rating, x_test_category, x_test_word_category], y_test, verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YLP6gU1PlDw",
        "outputId": "e34a3388-2b20-4d87-f83a-af7a70eda332"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "127/127 [==============================] - 4s 28ms/step\n",
            "Test accuracy: 0.9250741839762612\n",
            "Test precision: 0.8904235727440147\n",
            "Test recall: 0.9674837418709354\n",
            "Test F1 score: 0.9273555502277633\n",
            "Test ROC-AUC score: 0.9862607342791201\n",
            "Test confusion matrix:\n",
            " [[1807  238]\n",
            " [  65 1934]]\n"
          ]
        }
      ],
      "source": [
        "# Get predictions \n",
        "y_prob = model.predict([x_test_review_pad, x_test_rating, x_test_category, x_test_word_category])\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "test_metrics = evaluate_model(y_prob, y_test)\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print('Test accuracy:', test_metrics['accuracy'])\n",
        "print('Test precision:', test_metrics['precision'])\n",
        "print('Test recall:', test_metrics['recall'])\n",
        "print('Test F1 score:', test_metrics['f1'])\n",
        "print('Test ROC-AUC score:', test_metrics['roc_auc'])\n",
        "print('Test confusion matrix:\\n', test_metrics['confusion_matrix'])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "8bMJMmJ9Qd8D",
        "6RYUv70FUeEy",
        "j3B1DAhsUPlH",
        "06eaWzzjT9Fh",
        "Ln7Iqgl3MnxE"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "tenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
