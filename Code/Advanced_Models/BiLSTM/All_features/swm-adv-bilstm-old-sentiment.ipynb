{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIJjlEdZigV1",
        "outputId": "d53a8877-d550-4452-8a4d-2ffde5eade66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iMPRZMysij1_"
      },
      "outputs": [],
      "source": [
        "!pip install wget\n",
        "!pip install keras_preprocessing\n",
        "!pip install keras_tuner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "TwYmLcU8iHob"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "from tqdm import tqdm\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, LSTM, Dense, SpatialDropout1D, Dropout, Bidirectional, Input, Concatenate, concatenate\n",
        "from keras.initializers import Constant\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.optimizers import Adam\n",
        "import tensorflow as tf\n",
        "import keras_tuner as kt\n",
        "from keras.models import Model\n",
        "\n",
        "import os.path\n",
        "import wget\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "4bXyVUvCiLLY"
      },
      "outputs": [],
      "source": [
        "def assign_class(label):\n",
        "    if label == \"OR\":\n",
        "        return 0\n",
        "    else:\n",
        "        return 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Sr1lsLTs-V8u"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
        "\n",
        "def evaluate_model(y_prob, y_test):\n",
        "    y_pred = np.round(y_prob)\n",
        "    y_true = y_test\n",
        "\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred)\n",
        "    recall = recall_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    roc_auc = roc_auc_score(y_test, y_prob, multi_class='ovr')\n",
        "\n",
        "    metrics = {'accuracy': accuracy,\n",
        "               'precision': precision,\n",
        "               'recall': recall,\n",
        "               'f1': f1,\n",
        "               'confusion_matrix': cm,\n",
        "               'roc_auc': roc_auc}\n",
        "\n",
        "    return metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "U1dH60Pfkkr7"
      },
      "outputs": [],
      "source": [
        "# import and extract information \n",
        "\n",
        "ori_train_data = pd.read_csv('/content/drive/MyDrive/swm-data/ori_data_final_train.csv')\n",
        "ori_valid_data = pd.read_csv('/content/drive/MyDrive/swm-data/ori_data_final_val.csv')\n",
        "ori_test_data = pd.read_csv('/content/drive/MyDrive/swm-data/ori_data_final_test.csv')\n",
        "\n",
        "ori_train_data['label_final'] = ori_train_data['label'].apply(assign_class)\n",
        "ori_valid_data['label_final'] = ori_valid_data['label'].apply(assign_class)\n",
        "ori_test_data['label_final'] = ori_test_data['label'].apply(assign_class)\n",
        "\n",
        "ori_train_data.category = pd.factorize(ori_train_data.category)[0]\n",
        "ori_test_data.category = pd.factorize(ori_test_data.category)[0]\n",
        "ori_valid_data.category = pd.factorize(ori_valid_data.category)[0]\n",
        "category_indices = pd.factorize(ori_train_data.category)[1]\n",
        "\n",
        "x_train_review = ori_train_data.text_final\n",
        "x_train_sentiment = ori_train_data.sentiment\n",
        "x_train_category = ori_train_data.category\n",
        "x_train_word_category = ori_train_data.word_count_categories\n",
        "\n",
        "x_test_review = ori_test_data.text_final\n",
        "x_test_sentiment = ori_test_data.sentiment\n",
        "x_test_category = ori_test_data.category\n",
        "x_test_word_category = ori_test_data.word_count_categories\n",
        "\n",
        "\n",
        "x_val_review = ori_valid_data.text_final\n",
        "x_val_sentiment = ori_valid_data.sentiment\n",
        "x_val_category = ori_valid_data.category\n",
        "x_val_word_category = ori_valid_data.word_count_categories\n",
        "\n",
        "\n",
        "y_train = ori_train_data.label_final\n",
        "y_test = ori_test_data.label_final\n",
        "y_val = ori_valid_data.label_final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Mi_k0v_ukrY8"
      },
      "outputs": [],
      "source": [
        "# create vocab \n",
        "\n",
        "vocab_size = 20000\n",
        "oov_token = \"\"\n",
        "max_length = 200\n",
        "padding_type = \"post\"\n",
        "trunc_type = \"post\"\n",
        "\n",
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_token)\n",
        "tokenizer.fit_on_texts(x_train_review) \n",
        "\n",
        "x_train_review_pad = pad_sequences(tokenizer.texts_to_sequences(\n",
        "    x_train_review), maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "x_test_review_pad = pad_sequences(tokenizer.texts_to_sequences(\n",
        "    x_test_review), maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "x_val_review_pad = pad_sequences(tokenizer.texts_to_sequences(\n",
        "    x_val_review), maxlen=max_length, padding=padding_type, truncating=trunc_type)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hr3dtKJCrW5P",
        "outputId": "31e4ba51-40dc-4eb9-a83c-f43106c622bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 400000 word vectors.\n",
            "Converted 30442 words (7491 misses)\n"
          ]
        }
      ],
      "source": [
        "# if not os.path.isfile('/content/drive/MyDrive/swm-data/glove.6B.@00d.txt'):\n",
        "#     # large file, might take a while to download :)\n",
        "#     url = 'http://nlp.stanford.edu/data/glove.6B.zip'\n",
        "#     print('Downloading Pre-trained Word Embeddings')\n",
        "#     wget.download(url)\n",
        "#     print('Download Completed!\\nUnzipping...')\n",
        "#     shutil.unpack_archive('glove.6B.zip')\n",
        "\n",
        "embeddings_index = {}\n",
        "with open(\"/content/drive/MyDrive/swm-data/glove.6B.200d.txt\") as f:\n",
        "    for line in f:\n",
        "        word, coefs = line.split(maxsplit=1)\n",
        "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
        "        embeddings_index[word] = coefs\n",
        "\n",
        "print(\"Found %s word vectors.\" % len(embeddings_index))\n",
        "\n",
        "num_tokens = len(tokenizer.word_index) + 2\n",
        "embedding_dim = 200\n",
        "hits = 0\n",
        "misses = 0\n",
        "\n",
        "# Prepare embedding matrix\n",
        "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # Words not found in embedding index will be all-zeros.\n",
        "        # This includes the representation for \"padding\" and \"OOV\"\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "        hits += 1\n",
        "    else:\n",
        "        misses += 1\n",
        "print(\"Converted %d words (%d misses)\" % (hits, misses))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ZCaEGs8ZlB0_"
      },
      "outputs": [],
      "source": [
        "# create embedding layer \n",
        "import keras\n",
        "from keras.layers import Embedding\n",
        "\n",
        "embedding_layer = Embedding(\n",
        "    num_tokens,\n",
        "    embedding_dim,\n",
        "    embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
        "    trainable=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "81GPkGVomszJ"
      },
      "outputs": [],
      "source": [
        "def build_model(hp):\n",
        "\n",
        "    review_branch_input = Input(shape=(200,), name='review_input')\n",
        "    review_branch = embedding_layer(review_branch_input)\n",
        "    review_branch = Dropout(0.2)(review_branch)\n",
        "    review_branch = Bidirectional(\n",
        "        LSTM(64, dropout=0.2, recurrent_dropout=0))(review_branch)\n",
        "    review_branch = Dense(64, activation='relu')(review_branch)\n",
        "    review_branch_output = Dense(16, activation='relu')(review_branch)\n",
        "\n",
        "    sentiment_branch_input = Input(shape=(1,), name='sentiment_input')\n",
        "    sentiment_branch = Dense(8, activation='relu')(sentiment_branch_input)\n",
        "    sentiment_branch = Dropout(0.2)(sentiment_branch)\n",
        "    sentiment_branch_output = Dense(16, activation='relu')(sentiment_branch)\n",
        "\n",
        "    category_branch_input = Input(\n",
        "        shape=(1,), name='category_input')\n",
        "    category_branch = Dense(\n",
        "        8, activation='relu')(category_branch_input)\n",
        "    category_branch = Dropout(0.2)(category_branch)\n",
        "    category_branch_output = Dense(\n",
        "        16, activation='relu')(category_branch)\n",
        "\n",
        "    word_category_branch_input = Input(\n",
        "        shape=(1,), name='word_category_input')\n",
        "    word_category_branch = Dense(\n",
        "        8, activation='relu')(word_category_branch_input)\n",
        "    word_category_branch = Dropout(0.2)(word_category_branch)\n",
        "    word_category_branch_output = Dense(\n",
        "        16, activation='relu')(word_category_branch)\n",
        "\n",
        "    concat = concatenate([review_branch_output, sentiment_branch_output,\n",
        "                        category_branch_output, word_category_branch_output], name='Concatenate')\n",
        "\n",
        "    final_output = Dense(8, activation='relu')(concat)\n",
        "    final_output = Dense(1, activation='sigmoid')(final_output)\n",
        "\n",
        "    model = Model(inputs=[review_branch_input, sentiment_branch_input,\n",
        "                category_branch_input, word_category_branch_input], outputs=final_output, name='Final_output')\n",
        "\n",
        "    hp_learning_rate = hp.Float(\n",
        "        'learning_rate',\n",
        "        min_value=0.001,\n",
        "        max_value=0.005,\n",
        "        sampling='LOG',\n",
        "        default=1e-3\n",
        "    )\n",
        "\n",
        "    # clip value to avoid the gradient exploding\n",
        "    optimzer = Adam(clipvalue=0.5, learning_rate=hp_learning_rate)\n",
        "\n",
        "    model.compile(optimizer=optimzer,\n",
        "                loss='binary_crossentropy',\n",
        "                metrics=['acc'])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "n6kTImhHm6Rq"
      },
      "outputs": [],
      "source": [
        "tuner = kt.BayesianOptimization(build_model,\n",
        "                    objective='val_acc',\n",
        "                    max_trials=5,\n",
        "                    directory='adl4nlp',\n",
        "                    project_name='text_classification_bo')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1o7z9_5Mm80K",
        "outputId": "fad8813d-389f-484a-efac-c3c88a9a82a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Search space summary\n",
            "Default search space size: 1\n",
            "learning_rate (Float)\n",
            "{'default': 0.001, 'conditions': [], 'min_value': 0.001, 'max_value': 0.005, 'step': None, 'sampling': 'log'}\n"
          ]
        }
      ],
      "source": [
        "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)\n",
        "tuner.search_space_summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFwc7eQiuOax",
        "outputId": "c3d8f62b-221b-4b9b-c715-6a923ddcc0da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 5 Complete [00h 02m 32s]\n",
            "val_acc: 0.5562701225280762\n",
            "\n",
            "Best val_acc So Far: 0.9391540884971619\n",
            "Total elapsed time: 00h 10m 34s\n"
          ]
        }
      ],
      "source": [
        "tuner.search([x_train_review_pad,x_train_sentiment,x_train_category,x_train_word_category], y_train, epochs=5, \n",
        "         validation_data=([x_val_review_pad,x_val_sentiment,x_val_category,x_val_word_category], y_val),\n",
        "         callbacks=[stop_early,tf.keras.callbacks.TensorBoard(\"/tmp/tb_logs\")])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Wwfi692KzcU",
        "outputId": "7495f35e-cdcb-4041-fd41-b9893813f5ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results summary\n",
            "Results in adl4nlp/text_classification_bo\n",
            "Showing 10 best trials\n",
            "Objective(name=\"val_acc\", direction=\"max\")\n",
            "\n",
            "Trial 3 summary\n",
            "Hyperparameters:\n",
            "learning_rate: 0.0013365261252787552\n",
            "Score: 0.9391540884971619\n",
            "\n",
            "Trial 2 summary\n",
            "Hyperparameters:\n",
            "learning_rate: 0.0028482248953451807\n",
            "Score: 0.930744469165802\n",
            "\n",
            "Trial 1 summary\n",
            "Hyperparameters:\n",
            "learning_rate: 0.0011126288202267846\n",
            "Score: 0.9304971694946289\n",
            "\n",
            "Trial 0 summary\n",
            "Hyperparameters:\n",
            "learning_rate: 0.001662351213724624\n",
            "Score: 0.9265397191047668\n",
            "\n",
            "Trial 4 summary\n",
            "Hyperparameters:\n",
            "learning_rate: 0.0035473754142160813\n",
            "Score: 0.5562701225280762\n"
          ]
        }
      ],
      "source": [
        "tuner.results_summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "bM4x2XSrK3t9"
      },
      "outputs": [],
      "source": [
        "best_model = tuner.get_best_models(num_models=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "r4yLrOZ_PO0c"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "tf.config.run_functions_eagerly(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7Qn-rg8K4q8",
        "outputId": "e4020786-beb6-4e86-df62-37e49e798375"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/tensorflow/python/data/ops/structured_function.py:254: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "127/127 - 5s - loss: 0.1621 - acc: 0.9340 - 5s/epoch - 40ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.16208162903785706, 0.9339762330055237]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# evaluate and save model \n",
        "\n",
        "best_model[0].evaluate([x_test_review_pad, x_test_sentiment, x_test_category, x_test_word_category], y_test, verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "PKIle1VXLHp4"
      },
      "outputs": [],
      "source": [
        "best_model[0].save('/content/drive/MyDrive/swm-data/bilstm_old_ts.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RvxpIKwXLdsf",
        "outputId": "250758f7-0905-4c18-baad-22f4d2219b8b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/tensorflow/python/data/ops/structured_function.py:254: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "127/127 - 9s - loss: 0.1621 - acc: 0.9340 - 9s/epoch - 68ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.16208162903785706, 0.9339762330055237]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Reload the model and verify the accuracy.\n",
        "\n",
        "model = tf.keras.models.load_model('/content/drive/MyDrive/swm-data/bilstm_old_ts.h5')\n",
        "model.evaluate([x_test_review_pad, x_test_sentiment, x_test_category, x_test_word_category], y_test, verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQLfYQ-TDYwR",
        "outputId": "70901877-4234-4fea-ac21-4aa52e019d32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "127/127 [==============================] - 6s 46ms/step\n",
            "Test accuracy: 0.9339762611275965\n",
            "Test precision: 0.922439024390244\n",
            "Test recall: 0.9459729864932466\n",
            "Test F1 score: 0.934057792047419\n",
            "Test ROC-AUC score: 0.9846380402915395\n",
            "Test confusion matrix:\n",
            " [[1886  159]\n",
            " [ 108 1891]]\n"
          ]
        }
      ],
      "source": [
        "# Get predictions \n",
        "y_prob = model.predict([x_test_review_pad, x_test_sentiment, x_test_category, x_test_word_category])\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "test_metrics = evaluate_model(y_prob, y_test)\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print('Test accuracy:', test_metrics['accuracy'])\n",
        "print('Test precision:', test_metrics['precision'])\n",
        "print('Test recall:', test_metrics['recall'])\n",
        "print('Test F1 score:', test_metrics['f1'])\n",
        "print('Test ROC-AUC score:', test_metrics['roc_auc'])\n",
        "print('Test confusion matrix:\\n', te\n",
        "      st_metrics['confusion_matrix'])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "8bMJMmJ9Qd8D",
        "6RYUv70FUeEy",
        "j3B1DAhsUPlH",
        "06eaWzzjT9Fh",
        "Ln7Iqgl3MnxE"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "tenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
